# 시각 장애인 보행 안전 보조 앱 Smart Rod
### 내용 변경 사항에 대한 보다 면밀한 분석
 * ios용 제작 계획은 기존의 확정적에서 잠정적으로
 * 이유: 아래에서 언급할 인식률 및 완성도를 높이는 것에 좀 더 중점을 두기 위해서

---
### 완성도를 높이는 데에 있어서 가장 어려운 부분 식별
 1. 장애물에 대한 인식률 향상
 2. 앱 음성 인식 안정성 제고
---
### 해당 부분에 대한 공략 전략 
 * 데이터셋 구축의 완성도 향상 
  ```
 다양한 상황(낮,밤)에서 물체를 찍은 영상을 프레임 단위로 이용하여 dataset 구축

 ```
 * 얻은 데이터셋을 training set 과 validation set으로 어떻게 나눌 것인지 결정

 ```
 training set과 validation set을 몇 대 몇으로 나눌 것인지

 ```
 * 주어진 dataset에 최적화 되어 인식률을 높일 수 있는 learning rate/batch size/gradient function 탐색
 * 다양한 test set을 통해서 기계학습 실행
```
YOLO NN뿐만 아니라 그 외의 신경망들도 채택하여 학습 시도

```
```
 * 주의점: 앱에서 사용하기 위해서는 .tflite 가중치 파일로 전환을 해야하는데, 여러 신경망을 채택하는 경우, 
 * 이 .tflite 파일로 전환하는 과정에서 metadata 추가를 따로 해주거나 다른 종속적인 것을 처리해줘야 하는 
 * 경우가 있어서 이를 고려하여 앱에 tflite 가중치 파일을 반영해야 함.
```
 * 인식률 목표 : 
  - precision = 0.9 이상
  - recall = 0.9 이상
  - f1 score = 0.8 이상

 * 음성 인식이 끝나기 전에 사용자가 해당 기능을 음성으로 발화하면 기능이 실행되도록 개선
 ---
### 대표 시연 시나리오
 * 사용자가 보행 시 앱 기능 음성을 통해 실행
 * 보행 안내 서비스 실행
 * 장애물 탐지 및 음성 안내
 * 긴급 상황 발생 시 미리 등록된 번호로 음성을 통해 바로 연락
 * 현재 위치에서 가장 가까운 건물이 궁금한 경우 가까운 건물 찾기 기능을 통해 음성으로 안내



